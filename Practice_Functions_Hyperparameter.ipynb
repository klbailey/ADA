{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "1. Dataset\n",
        "\n",
        "  The dataset you will be using for this lab session: https://www.kaggle.com/datasets/muhammadbinimran/housing-price-prediction-data/code\n",
        "\n",
        "2. Splitting the Data:\n",
        "\n",
        "  Experiment with two different data splits:\n",
        "  * 80-20 split\n",
        "  * 70-30 split\n",
        "\n",
        "3. Multiple Linear Regression and Random Forest:\n",
        "\n",
        "\n",
        "4. Benchmarking:\n",
        "\n",
        "  Compare and benchmark the performance of the two classification models. Document your observations.\n",
        "\n",
        "\n",
        "6. **Recall**: Creating Python functions to streamline your Machine Learning process (code reusability)"
      ],
      "metadata": {
        "id": "OitP9J3WiCBu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# How to make functions in Python?\n",
        "\n",
        "- Use the `def` keyword, followed by the name of your function.\n",
        "- Inside the `()` includes your function parameters (inputs).\n",
        "```\n",
        "def add_numbers(a, b):\n",
        "    return a+b\n",
        "```\n",
        "```\n",
        "# to call this function:\n",
        "add_numbers(5, 7) # expected output should be 12\n",
        "```"
      ],
      "metadata": {
        "id": "s5TX0tkQDvk5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### More examples:\n",
        "```\n",
        "def\n",
        "```"
      ],
      "metadata": {
        "id": "95H7gDSEFuDb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import the libraries"
      ],
      "metadata": {
        "id": "iRAnoDraKRZ6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import sklearn.preprocessing as preprocessing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_selection import SelectKBest, f_regression\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.linear_model import LinearRegression"
      ],
      "metadata": {
        "id": "e6xP2qC-vjz9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loading Data"
      ],
      "metadata": {
        "id": "4u6PZay8vcaj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to load data\n",
        "def load_data(filepath):\n",
        "    df = pd.read_csv(filepath)\n",
        "    return df\n",
        "\n",
        "# Call the load_data function\n",
        "df = load_data('housing_price_dataset.csv')\n",
        "\n",
        "# Display the first few rows of the dataframe to confirm it loaded correctly\n",
        "print(df.head())\n"
      ],
      "metadata": {
        "id": "vXYctYjoBjlj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1d4e9776-c323-42b2-f0cc-3fd892e4b0a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   SquareFeet  Bedrooms  Bathrooms Neighborhood  YearBuilt          Price\n",
            "0        2126         4          1        Rural       1969  215355.283618\n",
            "1        2459         3          2        Rural       1980  195014.221626\n",
            "2        1860         2          1       Suburb       1970  306891.012076\n",
            "3        2294         2          1        Urban       1996  206786.787153\n",
            "4        2130         5          2       Suburb       2001  272436.239065\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "I choose not to download from kaggle directly as datasets change or are removed."
      ],
      "metadata": {
        "id": "2IlQ86fWZA6k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocessing"
      ],
      "metadata": {
        "id": "hwAKnyUlv5fD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function for preprocessing data\n",
        "def preprocess_data(df):\n",
        "    df['Price'] = df['Price'].abs()\n",
        "    df['Price'].describe()  # You can optionally print or log this if needed\n",
        "    df = df.iloc[:10000, :]\n",
        "    new_neighborhood = preprocessing.LabelEncoder().fit_transform(df['Neighborhood'])\n",
        "    df['Neighborhood'] = new_neighborhood\n",
        "    return df\n",
        "\n",
        "# Call the preprocess_data function\n",
        "df = preprocess_data(df)\n",
        "\n",
        "# Display the first few rows of the preprocessed dataframe\n",
        "print(df.head())"
      ],
      "metadata": {
        "id": "8v41UYb_vyw-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9390695f-c8fc-491e-f826-0e5264113c65"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   SquareFeet  Bedrooms  Bathrooms  Neighborhood  YearBuilt          Price\n",
            "0        2126         4          1             0       1969  215355.283618\n",
            "1        2459         3          2             0       1980  195014.221626\n",
            "2        1860         2          1             1       1970  306891.012076\n",
            "3        2294         2          1             2       1996  206786.787153\n",
            "4        2130         5          2             1       2001  272436.239065\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-98-2d6d464b5e33>:7: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['Neighborhood'] = new_neighborhood\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Return absolute value for Price getting rid of negative value in 'Price'. Get first 10,000 rows for tuning. Transform 'Neighborhood'."
      ],
      "metadata": {
        "id": "XxlSajf5MQ15"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Feature Selection"
      ],
      "metadata": {
        "id": "L6MzWT5uMhDD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define features and target variable\n",
        "X = df.drop('Price', axis=1)  # Features\n",
        "y = df['Price']               # Target variable\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "\n",
        "# Function for feature selection\n",
        "def select_features(X_train, y_train, X_test, k=3):\n",
        "    selector = SelectKBest(score_func=f_regression, k=k)\n",
        "    X_train = selector.fit_transform(X_train, y_train)\n",
        "    X_test = selector.transform(X_test)\n",
        "    return X_train, X_test\n",
        "\n",
        "# Call select_features function\n",
        "X_train_selected, X_test_selected = select_features(X_train, y_train, X_test, k=3)\n",
        "\n"
      ],
      "metadata": {
        "id": "bBRIJQzEMif8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Multiple Linear Regression and Random Forest Regression"
      ],
      "metadata": {
        "id": "qSwg67e42A00"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "\n",
        "# Function to SPLIT data\n",
        "def split_data(X, y, test_sizes: list, random_state=None):\n",
        "    splits = {}\n",
        "    for test_size in test_sizes:\n",
        "        X_train, X_test, y_train, y_test = train_test_split(\n",
        "            X, y, test_size=test_size, random_state=random_state\n",
        "        )\n",
        "        splits[test_size] = {\n",
        "            \"X_train\": X_train,\n",
        "            \"X_test\": X_test,\n",
        "            \"y_train\": y_train,\n",
        "            \"y_test\": y_test,\n",
        "        }\n",
        "    return splits\n",
        "\n",
        "# Generalized function to TRAIN and PREDICT with any model\n",
        "def train_and_predict(model, X_train, y_train, X_test):\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "    return y_pred\n",
        "\n",
        "# Function to calculate EVALUATION metrics\n",
        "def calculate_metrics(y_true, y_pred):\n",
        "    mae = mean_absolute_error(y_true, y_pred)\n",
        "    mse = mean_squared_error(y_true, y_pred)\n",
        "    rmse = np.sqrt(mse)\n",
        "    r2 = r2_score(y_true, y_pred)\n",
        "    mape = np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
        "    return mae, mse, rmse, r2, mape\n",
        "\n",
        "# Function to EVALUATE multiple models with different splits\n",
        "def evaluate_models(X, y, test_sizes, models, random_state=None):\n",
        "    data_splits = split_data(X, y, test_sizes, random_state)\n",
        "\n",
        "    all_results = {}\n",
        "    for model_name, model in models.items():\n",
        "        results = {}\n",
        "        for test_size, split in data_splits.items():\n",
        "            # Train and predict for TRAINING set\n",
        "            y_train_pred = train_and_predict(model, split['X_train'], split['y_train'], split['X_train'])\n",
        "            y_test_pred = train_and_predict(model, split['X_train'], split['y_train'], split['X_test'])\n",
        "\n",
        "            # Calculate metrics for TRAINING set\n",
        "            train_mae, train_mse, train_rmse, train_r2, train_mape = calculate_metrics(split['y_train'], y_train_pred)\n",
        "            # Calculate metrics for TEST set\n",
        "            test_mae, test_mse, test_rmse, test_r2, test_mape = calculate_metrics(split['y_test'], y_test_pred)\n",
        "\n",
        "            results[test_size] = {\n",
        "                'Train': {\n",
        "                    'MAE': train_mae,\n",
        "                    'MSE': train_mse,\n",
        "                    'RMSE': train_rmse,\n",
        "                    'R^2': train_r2,\n",
        "                    'MAPE': train_mape\n",
        "                },\n",
        "                'Test': {\n",
        "                    'MAE': test_mae,\n",
        "                    'MSE': test_mse,\n",
        "                    'RMSE': test_rmse,\n",
        "                    'R^2': test_r2,\n",
        "                    'MAPE': test_mape\n",
        "                }\n",
        "            }\n",
        "        all_results[model_name] = results\n",
        "    return all_results\n",
        "\n",
        "# Define models\n",
        "models = {\n",
        "    'Linear Regression': LinearRegression(),\n",
        "    'Random Forest Regression': RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "}\n",
        "\n",
        "# Usage\n",
        "test_sizes = [0.2, 0.3]\n",
        "results = evaluate_models(X, y, test_sizes, models, random_state=42)\n",
        "\n",
        "# Display results for each model and test size\n",
        "for model_name, res in results.items():\n",
        "    print()\n",
        "    print(f\"Evaluation for {model_name}:\")\n",
        "    for test_size, metrics in res.items():\n",
        "        print(f\"\\nTest Size: {test_size}\")\n",
        "        print(f\"Train - MAE: {metrics['Train']['MAE']:.4f}, MSE: {metrics['Train']['MSE']:.4f}, RMSE: {metrics['Train']['RMSE']:.4f}, R^2: {metrics['Train']['R^2']:.4f}, MAPE: {metrics['Train']['MAPE']:.2f}%\")\n",
        "        print(f\"Test  - MAE: {metrics['Test']['MAE']:.4f}, MSE: {metrics['Test']['MSE']:.4f}, RMSE: {metrics['Test']['RMSE']:.4f}, R^2: {metrics['Test']['R^2']:.4f}, MAPE: {metrics['Test']['MAPE']:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ex-4wHMocp1m",
        "outputId": "58d23146-697e-40a0-cac5-b1425cc24110"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Evaluation for Linear Regression:\n",
            "\n",
            "Test Size: 0.2\n",
            "Train - MAE: 40356.5020, MSE: 2549096747.4459, RMSE: 50488.5804, R^2: 0.5551, MAPE: 24.51%\n",
            "Test  - MAE: 40765.4492, MSE: 2564777435.9967, RMSE: 50643.6317, R^2: 0.5732, MAPE: 27.40%\n",
            "\n",
            "Test Size: 0.3\n",
            "Train - MAE: 40427.5430, MSE: 2552133934.3296, RMSE: 50518.6494, R^2: 0.5548, MAPE: 24.42%\n",
            "Test  - MAE: 40475.3061, MSE: 2553086568.9581, RMSE: 50528.0770, R^2: 0.5680, MAPE: 26.79%\n",
            "\n",
            "Evaluation for Random Forest Regression:\n",
            "\n",
            "Test Size: 0.2\n",
            "Train - MAE: 15843.0191, MSE: 403223965.3826, RMSE: 20080.4374, R^2: 0.9296, MAPE: 9.49%\n",
            "Test  - MAE: 43045.7923, MSE: 2887255915.9704, RMSE: 53733.1919, R^2: 0.5195, MAPE: 28.83%\n",
            "\n",
            "Test Size: 0.3\n",
            "Train - MAE: 15959.9025, MSE: 409183953.9074, RMSE: 20228.2959, R^2: 0.9286, MAPE: 9.53%\n",
            "Test  - MAE: 42995.9320, MSE: 2909144390.0158, RMSE: 53936.4848, R^2: 0.5078, MAPE: 28.22%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Linear Regression:**\n",
        "\n",
        "MAE, MSE, RMSE values are slightly higher for the test set. R^2 is lower on the test set. MAPE is slightly higher for the test set. The 80 20 split has a slightly better performance on the test set with lower error metrics and higher R^2.\n",
        "\n",
        "**Random Forest Regression:**\n",
        "\n",
        "MAE, RMSE and MAPE are higher on the test set indicating prediction errors are larger on the test set. The R^2 is lower on the test data suggesting it does not generalize well to the unseen data. The 70 30 split is marginally better in performance, but still lower than its training performance.\n",
        "\n",
        "Both show decrease in performance on the test set compared to the training set."
      ],
      "metadata": {
        "id": "xU9FL65mYNbP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Benchmarking"
      ],
      "metadata": {
        "id": "AEBFEDNjYCZF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<!DOCTYPE html>\n",
        "<html>\n",
        "<head>\n",
        "    <style>\n",
        "        table {\n",
        "            width: 100%;\n",
        "            border-collapse: collapse;\n",
        "        }\n",
        "        th, td {\n",
        "            border: 1px solid #ddd;\n",
        "            padding: 8px;\n",
        "        }\n",
        "        th {\n",
        "            background-color: #f2f2f2;\n",
        "            text-align: center;\n",
        "        }\n",
        "        .model-header {\n",
        "            background-color: #e0e0e0;\n",
        "            text-align: center;\n",
        "            font-weight: bold;\n",
        "        }\n",
        "        .model-subheader {\n",
        "            background-color: #d0d0d0;\n",
        "            text-align: center;\n",
        "            font-weight: bold;\n",
        "        }\n",
        "        .metrics-header {\n",
        "            background-color: #ffffff;\n",
        "            text-align: center;\n",
        "        }\n",
        "        .split-row {\n",
        "            background-color: #f9f9f9;\n",
        "        }\n",
        "        .divider {\n",
        "            border-bottom: 2px solid #ddd;\n",
        "        }\n",
        "    </style>\n",
        "</head>\n",
        "<body>\n",
        "\n",
        "<h2>RandomForestRegressor vs LinearRegression</h2>\n",
        "\n",
        "<table>\n",
        "    <thead>\n",
        "        <tr>\n",
        "            <th>Split</th>\n",
        "            <th>Metric</th>\n",
        "            <th class=\"model-header\" colspan=\"2\">RandomForestRegressor</th>\n",
        "            <th class=\"model-header\" colspan=\"2\">LinearRegression</th>\n",
        "        </tr>\n",
        "        <tr>\n",
        "            <th></th>\n",
        "            <th></th>\n",
        "            <th class=\"model-subheader\">Train</th>\n",
        "            <th class=\"model-subheader\">Test</th>\n",
        "            <th class=\"model-subheader\">Train</th>\n",
        "            <th class=\"model-subheader\">Test</th>\n",
        "        </tr>\n",
        "    </thead>\n",
        "    <tbody>\n",
        "        <tr class=\"split-row\">\n",
        "            <td>80:20</td>\n",
        "            <td>MAE</td>\n",
        "            <td>15843.0191</td>\n",
        "            <td>43045.7923</td>\n",
        "            <td>40356.5020</td>\n",
        "            <td>40765.4492</td>\n",
        "        </tr>\n",
        "        <tr>\n",
        "            <td></td>\n",
        "            <td>MSE</td>\n",
        "            <td>403223965.3826</td>\n",
        "            <td>2887255915.9704</td>\n",
        "            <td>2549096747.4459</td>\n",
        "            <td>2564777435.9967</td>\n",
        "        </tr>\n",
        "        <tr>\n",
        "            <td></td>\n",
        "            <td>RMSE</td>\n",
        "            <td>20080.4374</td>\n",
        "            <td>53733.1919</td>\n",
        "            <td>50488.5804</td>\n",
        "            <td>50643.6317</td>\n",
        "        </tr>\n",
        "        <tr>\n",
        "            <td></td>\n",
        "            <td>R²</td>\n",
        "            <td>0.9296</td>\n",
        "            <td>0.5195</td>\n",
        "            <td>0.5551</td>\n",
        "            <td>0.5732</td>\n",
        "        </tr>\n",
        "        <tr>\n",
        "            <td></td>\n",
        "            <td>MAPE</td>\n",
        "            <td>9.49%</td>\n",
        "            <td>28.83%</td>\n",
        "            <td>24.51%</td>\n",
        "            <td>27.40%</td>\n",
        "        </tr>\n",
        "        <tr class=\"divider\">\n",
        "            <td colspan=\"6\"></td>\n",
        "        </tr>\n",
        "        <tr class=\"split-row\">\n",
        "            <td>70:30</td>\n",
        "            <td>MAE</td>\n",
        "            <td>15959.9025</td>\n",
        "            <td>42995.9320</td>\n",
        "            <td>40427.5430</td>\n",
        "            <td>40475.3061</td>\n",
        "        </tr>\n",
        "        <tr>\n",
        "            <td></td>\n",
        "            <td>MSE</td>\n",
        "            <td>409183953.9074</td>\n",
        "            <td>2909144390.0158</td>\n",
        "            <td>2552133934.3296</td>\n",
        "            <td>2553086568.9581</td>\n",
        "        </tr>\n",
        "        <tr>\n",
        "            <td></td>\n",
        "            <td>RMSE</td>\n",
        "            <td>20228.2959</td>\n",
        "            <td>53936.4848</td>\n",
        "            <td>50518.6494</td>\n",
        "            <td>50528.0770</td>\n",
        "        </tr>\n",
        "        <tr>\n",
        "            <td></td>\n",
        "            <td>R²</td>\n",
        "            <td>0.9286</td>\n",
        "            <td>0.5078</td>\n",
        "            <td>0.5548</td>\n",
        "            <td>0.5680</td>\n",
        "        </tr>\n",
        "        <tr>\n",
        "            <td></td>\n",
        "            <td>MAPE</td>\n",
        "            <td>9.53%</td>\n",
        "            <td>28.22%</td>\n",
        "            <td>24.42%</td>\n",
        "            <td>26.79%</td>\n",
        "        </tr>\n",
        "    </tbody>\n",
        "</table>\n",
        "\n",
        "</body>\n",
        "</html>\n"
      ],
      "metadata": {
        "id": "wqAUAulUkNpK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Summary**\n",
        "\n",
        "\n",
        "Linear Regression performs with moderate overfitting as indicated by the higher test set error metrics and lower R^2 values. The 80:20 split slightly outperforms the 70:30 split.\n",
        "\n",
        "Random Forest Regressor demonstrates even higher test set error metrics and lower R^2 values, indicating a more significant generalization issue. The 80:20 split provides marginally better performance compared to the 70:30 split.\n",
        "\n",
        "**Overall Comparison:**\n",
        "\n",
        "Linear Regression offers more stable and less complex predictions with consistent performance, although with moderate overfitting.\n",
        "    \n",
        "Random Forest provides highly accurate training predictions but struggles with test data generalization, showing significant overfitting and reduced performance on unseen data.\n",
        "\n",
        "Both models have their strengths and weaknesses. Linear Regression may be preferable for its stability and interpretability, while Random Forest might be reconsidered with additional tuning to improve generalization."
      ],
      "metadata": {
        "id": "50dJLSJTdFMU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "fIg4XXY-qSaY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Default Parameters"
      ],
      "metadata": {
        "id": "DiK6hNADrPE3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_default_lr_params():\n",
        "    model = LinearRegression()\n",
        "    default_params = model.get_params()\n",
        "    print(\"\\nDefault Hyperparameters for LinearRegression:\")\n",
        "    for param, value in default_params.items():\n",
        "        print(f\"{param}: {value}\")\n",
        "    return default_params\n",
        "\n",
        "default_lr_params = get_default_lr_params()\n",
        "\n",
        "def get_default_rf_params():\n",
        "    model = RandomForestRegressor(random_state=23)\n",
        "    default_params = model.get_params()\n",
        "    print(\"\\nDefault Hyperparameters for RandomForestRegressor:\")\n",
        "    for param, value in default_params.items():\n",
        "        print(f\"{param}: {value}\")\n",
        "    return default_params\n",
        "\n",
        "default_rf_params = get_default_rf_params()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CdEwcK6pn7ca",
        "outputId": "23054f11-7520-46ed-dffc-810e509a7559"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Default Hyperparameters for LinearRegression:\n",
            "copy_X: True\n",
            "fit_intercept: True\n",
            "n_jobs: None\n",
            "positive: False\n",
            "\n",
            "Default Hyperparameters for RandomForestRegressor:\n",
            "bootstrap: True\n",
            "ccp_alpha: 0.0\n",
            "criterion: squared_error\n",
            "max_depth: None\n",
            "max_features: 1.0\n",
            "max_leaf_nodes: None\n",
            "max_samples: None\n",
            "min_impurity_decrease: 0.0\n",
            "min_samples_leaf: 1\n",
            "min_samples_split: 2\n",
            "min_weight_fraction_leaf: 0.0\n",
            "n_estimators: 100\n",
            "n_jobs: None\n",
            "oob_score: False\n",
            "random_state: 23\n",
            "verbose: 0\n",
            "warm_start: False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Parameter Grid"
      ],
      "metadata": {
        "id": "Ld2yIB3csb4r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def tune_linear_regression(X_train, y_train):\n",
        "    # Define the parameter grid for LinearRegression\n",
        "    param_grid = {\n",
        "        'fit_intercept': [True, False],\n",
        "        'copy_X': [True, False],\n",
        "        'positive': [True, False]\n",
        "    }\n",
        "\n",
        "    # Initialize the model\n",
        "    model = LinearRegression()\n",
        "\n",
        "    # Create GridSearchCV instance\n",
        "    grid_search = GridSearchCV(model, param_grid, cv=5, n_jobs=-1, error_score='raise')\n",
        "\n",
        "    # Fit model to perform search\n",
        "    grid_search.fit(X_train, y_train)\n",
        "\n",
        "    # Get best hyperparameters from the search\n",
        "    best_params = grid_search.best_params_\n",
        "\n",
        "    # Print the best hyperparameters\n",
        "    print(\"\\nBest Hyperparameters for LinearRegression:\")\n",
        "    for param, value in best_params.items():\n",
        "        print(f\"{param}: {value}\")\n",
        "\n",
        "    return best_params\n",
        "\n",
        "# Call the function to tune Linear Regression\n",
        "best_lr_params = tune_linear_regression(X_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wdWj74ejoMqk",
        "outputId": "942398e7-1e93-43a0-927d-342ba50edab1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Best Hyperparameters for LinearRegression:\n",
            "copy_X: True\n",
            "fit_intercept: True\n",
            "positive: True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def tune_random_forest(X_train, y_train):\n",
        "    # Define the parameter grid RandomForestRegressor\n",
        "    param_grid = {\n",
        "        'n_estimators': [50, 100, 200],         # Number of trees in the forest\n",
        "        'max_depth': [None, 10, 20],            # Maximum depth of the tree\n",
        "        'min_samples_split': [2, 5, 10],        # Minimum number of samples required to split an internal node\n",
        "    }\n",
        "\n",
        "    # Initialize the model\n",
        "    model = RandomForestRegressor(random_state=23)\n",
        "\n",
        "    # Create GridSearchCV instance\n",
        "    grid_search = GridSearchCV(model, param_grid, cv=5, n_jobs=-1, error_score='raise')\n",
        "\n",
        "    # Fit model to perform search\n",
        "    grid_search.fit(X_train, y_train)\n",
        "\n",
        "    # Get best hyperparameters from search\n",
        "    best_params = grid_search.best_params_\n",
        "\n",
        "    # Print best hyperparameters\n",
        "    print(\"\\nBest Hyperparameters for RandomForestRegressor:\")\n",
        "    for param, value in best_params.items():\n",
        "        print(f\"{param}: {value}\")\n",
        "\n",
        "    return best_params\n",
        "\n",
        "# Call the function to tune Random Forest Regressor\n",
        "best_rf_params = tune_random_forest(X_train, y_train)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cAh1NH0Ctx75",
        "outputId": "29368362-a5f2-47b6-b1ca-fcf1c0fcec6f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Best Hyperparameters for RandomForestRegressor:\n",
            "max_depth: 10\n",
            "min_samples_split: 10\n",
            "n_estimators: 200\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Redefine models with the best parameters, training, and predicting."
      ],
      "metadata": {
        "id": "a96JJ2_3tBOk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This block is for my testing only:"
      ],
      "metadata": {
        "id": "fIGcHLP0yBmw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model(y_true, y_pred):\n",
        "    \"\"\"\n",
        "    Evaluate the performance of a model using various metrics.\n",
        "\n",
        "    Parameters:\n",
        "    y_true (array-like): True values.\n",
        "    y_pred (array-like): Predicted values.\n",
        "\n",
        "    Returns:\n",
        "    tuple: MAE, MSE, RMSE, R², MAPE\n",
        "    \"\"\"\n",
        "    mae = mean_absolute_error(y_true, y_pred)\n",
        "    mse = mean_squared_error(y_true, y_pred)\n",
        "    rmse = np.sqrt(mse)\n",
        "    r2 = r2_score(y_true, y_pred)\n",
        "    mape = mean_absolute_percentage_error(y_true, y_pred) * 100\n",
        "    return mae, mse, rmse, r2, mape\n",
        "\n",
        "def train_predict_evaluate(X, y, test_size, best_lr_params, best_rf_params):\n",
        "    \"\"\"\n",
        "    Train, predict, and evaluate Linear Regression and Random Forest models.\n",
        "\n",
        "    Parameters:\n",
        "    X (array-like): Feature data.\n",
        "    y (array-like): Target data.\n",
        "    test_size (float): Proportion of data to be used as test set.\n",
        "    best_lr_params (dict): Best hyperparameters for Linear Regression.\n",
        "    best_rf_params (dict): Best hyperparameters for Random Forest.\n",
        "    \"\"\"\n",
        "    # SPLIT the data\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=23)\n",
        "\n",
        "    # Initialize models with best hyperparameters\n",
        "    # ** unpacks dictionary into keyword arguments when initializing model:\n",
        "    # lr_model = LinearRegression(**best_lr_params)\n",
        "    # then pulls {'fit_intercept': True, 'copy_X': True, 'positive': True} from best_lr_params = tune_linear_regression(X_train, y_train)\n",
        "    lr_model = LinearRegression(**best_lr_params)\n",
        "    rf_model = RandomForestRegressor(**best_rf_params, random_state=23)\n",
        "\n",
        "    print(\"Training Linear Regression...\")\n",
        "    # TRAIN models\n",
        "    lr_model.fit(X_train, y_train)\n",
        "    print(\"Training Random Forest...\")\n",
        "    rf_model.fit(X_train, y_train)\n",
        "\n",
        "    print(\"Predicting with Linear Regression...\")\n",
        "    # PREDICT\n",
        "    lr_predictions = lr_model.predict(X_test)\n",
        "    print(\"Predicting with Random Forest...\")\n",
        "    rf_predictions = rf_model.predict(X_test)\n",
        "\n",
        "    print(\"Evaluating Linear Regression...\")\n",
        "    # EVALUATE\n",
        "    lr_train_preds = lr_model.predict(X_train)\n",
        "    lr_train_metrics = evaluate_model(y_train, lr_train_preds)\n",
        "    lr_test_metrics = evaluate_model(y_test, lr_predictions)\n",
        "\n",
        "    print(\"Evaluating Random Forest...\")\n",
        "    rf_train_preds = rf_model.predict(X_train)\n",
        "    rf_train_metrics = evaluate_model(y_train, rf_train_preds)\n",
        "    rf_test_metrics = evaluate_model(y_test, rf_predictions)\n",
        "\n",
        "    # Print results\n",
        "    print(f\"\\nEvaluation for Linear Regression:\\n\")\n",
        "    print(f\"Test Size: {test_size}\")\n",
        "    print(f\"Train - MAE: {lr_train_metrics[0]:.4f}, MSE: {lr_train_metrics[1]:.4f}, RMSE: {lr_train_metrics[2]:.4f}, R²: {lr_train_metrics[3]:.4f}, MAPE: {lr_train_metrics[4]:.2f}%\")\n",
        "    print(f\"Test  - MAE: {lr_test_metrics[0]:.4f}, MSE: {lr_test_metrics[1]:.4f}, RMSE: {lr_test_metrics[2]:.4f}, R²: {lr_test_metrics[3]:.4f}, MAPE: {lr_test_metrics[4]:.2f}%\")\n",
        "\n",
        "    print(f\"\\nEvaluation for Random Forest Regression:\\n\")\n",
        "    print(f\"Test Size: {test_size}\")\n",
        "    print(f\"Train - MAE: {rf_train_metrics[0]:.4f}, MSE: {rf_train_metrics[1]:.4f}, RMSE: {rf_train_metrics[2]:.4f}, R²: {rf_train_metrics[3]:.4f}, MAPE: {rf_train_metrics[4]:.2f}%\")\n",
        "    print(f\"Test  - MAE: {rf_test_metrics[0]:.4f}, MSE: {rf_test_metrics[1]:.4f}, RMSE: {rf_test_metrics[2]:.4f}, R²: {rf_test_metrics[3]:.4f}, MAPE: {rf_test_metrics[4]:.2f}%\")\n",
        "\n",
        "# Call the function for both splits\n",
        "train_predict_evaluate(X, y, test_size=0.2, best_lr_params=best_lr_params, best_rf_params=best_rf_params)  # 80:20 split\n",
        "train_predict_evaluate(X, y, test_size=0.3, best_lr_params=best_lr_params, best_rf_params=best_rf_params)  # 70:30 split\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1OgxJzngv_BZ",
        "outputId": "a1cc47c4-1ce4-4b34-b3e9-cf5f7420711f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Linear Regression...\n",
            "Training Random Forest...\n",
            "Predicting with Linear Regression...\n",
            "Predicting with Random Forest...\n",
            "Evaluating Linear Regression...\n",
            "Evaluating Random Forest...\n",
            "\n",
            "Evaluation for Linear Regression:\n",
            "\n",
            "Test Size: 0.2\n",
            "Train - MAE: 40332.0570, MSE: 2531183459.4308, RMSE: 50310.8682, R²: 0.5632, MAPE: 2479.34%\n",
            "Test  - MAE: 40857.8027, MSE: 2636110412.8051, RMSE: 51343.0659, R²: 0.5417, MAPE: 2578.58%\n",
            "\n",
            "Evaluation for Random Forest Regression:\n",
            "\n",
            "Test Size: 0.2\n",
            "Train - MAE: 34213.0806, MSE: 1817997301.7465, RMSE: 42637.9796, R²: 0.6862, MAPE: 2097.63%\n",
            "Test  - MAE: 41542.4950, MSE: 2725642623.0416, RMSE: 52207.6874, R²: 0.5261, MAPE: 2616.49%\n",
            "Training Linear Regression...\n",
            "Training Random Forest...\n",
            "Predicting with Linear Regression...\n",
            "Predicting with Random Forest...\n",
            "Evaluating Linear Regression...\n",
            "Evaluating Random Forest...\n",
            "\n",
            "Evaluation for Linear Regression:\n",
            "\n",
            "Test Size: 0.3\n",
            "Train - MAE: 40106.5543, MSE: 2503198525.0461, RMSE: 50031.9750, R²: 0.5660, MAPE: 2450.53%\n",
            "Test  - MAE: 41222.8582, MSE: 2668651785.3561, RMSE: 51658.9952, R²: 0.5417, MAPE: 2616.92%\n",
            "\n",
            "Evaluation for Random Forest Regression:\n",
            "\n",
            "Test Size: 0.3\n",
            "Train - MAE: 33647.0758, MSE: 1758677570.8875, RMSE: 41936.5899, R²: 0.6951, MAPE: 2049.12%\n",
            "Test  - MAE: 41867.1083, MSE: 2749298093.3533, RMSE: 52433.7496, R²: 0.5278, MAPE: 2645.52%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model(y_true, y_pred):\n",
        "    \"\"\"\n",
        "    Evaluate the performance of a model using various metrics.\n",
        "\n",
        "    Parameters:\n",
        "    y_true (array-like): True values.\n",
        "    y_pred (array-like): Predicted values.\n",
        "\n",
        "    Returns:\n",
        "    tuple: MAE, MSE, RMSE, R², MAPE\n",
        "    \"\"\"\n",
        "    mae = mean_absolute_error(y_true, y_pred)\n",
        "    mse = mean_squared_error(y_true, y_pred)\n",
        "    rmse = np.sqrt(mse)\n",
        "    r2 = r2_score(y_true, y_pred)\n",
        "\n",
        "    # Adjust MAPE calculation to handle cases where y_true might be zero\n",
        "    epsilon = 1e-8  # Small constant to avoid division by zero\n",
        "    mape = np.mean(np.abs((y_true - y_pred) / np.maximum(np.abs(y_true), epsilon))) * 100\n",
        "\n",
        "    return mae, mse, rmse, r2, mape\n",
        "\n",
        "def train_predict_evaluate(X, y, test_size, best_lr_params, best_rf_params):\n",
        "    \"\"\"\n",
        "    Train, predict, and evaluate Linear Regression and Random Forest models.\n",
        "\n",
        "    Parameters:\n",
        "    X (array-like): Feature data.\n",
        "    y (array-like): Target data.\n",
        "    test_size (float): Proportion of data to be used as test set.\n",
        "    best_lr_params (dict): Best hyperparameters for Linear Regression.\n",
        "    best_rf_params (dict): Best hyperparameters for Random Forest.\n",
        "    \"\"\"\n",
        "    # SPLIT the data\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=23)\n",
        "\n",
        "    # Initialize models with best hyperparameters\n",
        "    # ** Unpacks dictionary into keyword arguments when initializing model:\n",
        "    #    lr_model = LinearRegression(**best_lr_params)\n",
        "    #    then pulls {'fit_intercept': True, 'copy_X': True, 'positive': True}\n",
        "    #    from best_lr_params = tune_linear_regression(X_train, y_train)\n",
        "    lr_model = LinearRegression(**best_lr_params)\n",
        "    rf_model = RandomForestRegressor(**best_rf_params, random_state=23)\n",
        "\n",
        "    # TRAIN models\n",
        "    lr_model.fit(X_train, y_train)\n",
        "    rf_model.fit(X_train, y_train)\n",
        "\n",
        "    # PREDICT\n",
        "    lr_train_preds = lr_model.predict(X_train)\n",
        "    lr_test_preds = lr_model.predict(X_test)\n",
        "    rf_train_preds = rf_model.predict(X_train)\n",
        "    rf_test_preds = rf_model.predict(X_test)\n",
        "\n",
        "    # EVALUATE\n",
        "    lr_train_metrics = evaluate_model(y_train, lr_train_preds)\n",
        "    lr_test_metrics = evaluate_model(y_test, lr_test_preds)\n",
        "    rf_train_metrics = evaluate_model(y_train, rf_train_preds)\n",
        "    rf_test_metrics = evaluate_model(y_test, rf_test_preds)\n",
        "\n",
        "    # Print results\n",
        "    print(f\"\\nEvaluation for Linear Regression:\\n\")\n",
        "    print(f\"Test Size: {test_size}\")\n",
        "    print(f\"Train - MAE: {lr_train_metrics[0]:.4f}, MSE: {lr_train_metrics[1]:.4f}, RMSE: {lr_train_metrics[2]:.4f}, R²: {lr_train_metrics[3]:.4f}, MAPE: {lr_train_metrics[4]:.2f}%\")\n",
        "    print(f\"Test  - MAE: {lr_test_metrics[0]:.4f}, MSE: {lr_test_metrics[1]:.4f}, RMSE: {lr_test_metrics[2]:.4f}, R²: {lr_test_metrics[3]:.4f}, MAPE: {lr_test_metrics[4]:.2f}%\")\n",
        "\n",
        "    print(f\"\\nEvaluation for Random Forest Regression:\\n\")\n",
        "    print(f\"Test Size: {test_size}\")\n",
        "    print(f\"Train - MAE: {rf_train_metrics[0]:.4f}, MSE: {rf_train_metrics[1]:.4f}, RMSE: {rf_train_metrics[2]:.4f}, R²: {rf_train_metrics[3]:.4f}, MAPE: {rf_train_metrics[4]:.2f}%\")\n",
        "    print(f\"Test  - MAE: {rf_test_metrics[0]:.4f}, MSE: {rf_test_metrics[1]:.4f}, RMSE: {rf_test_metrics[2]:.4f}, R²: {rf_test_metrics[3]:.4f}, MAPE: {rf_test_metrics[4]:.2f}%\")\n",
        "\n",
        "# Call the function for both splits\n",
        "train_predict_evaluate(X, y, test_size=0.2, best_lr_params=best_lr_params, best_rf_params=best_rf_params)  # 80:20 split\n",
        "train_predict_evaluate(X, y, test_size=0.3, best_lr_params=best_lr_params, best_rf_params=best_rf_params)  # 70:30 split\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jwGfeeXczmIs",
        "outputId": "1b9ccaa0-8b35-4772-b965-3b7a6a2c51b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Evaluation for Linear Regression:\n",
            "\n",
            "Test Size: 0.2\n",
            "Train - MAE: 40332.0570, MSE: 2531183459.4308, RMSE: 50310.8682, R²: 0.5632, MAPE: 24.79%\n",
            "Test  - MAE: 40857.8027, MSE: 2636110412.8051, RMSE: 51343.0659, R²: 0.5417, MAPE: 25.79%\n",
            "\n",
            "Evaluation for Random Forest Regression:\n",
            "\n",
            "Test Size: 0.2\n",
            "Train - MAE: 34213.0806, MSE: 1817997301.7465, RMSE: 42637.9796, R²: 0.6862, MAPE: 20.98%\n",
            "Test  - MAE: 41542.4950, MSE: 2725642623.0416, RMSE: 52207.6874, R²: 0.5261, MAPE: 26.16%\n",
            "\n",
            "Evaluation for Linear Regression:\n",
            "\n",
            "Test Size: 0.3\n",
            "Train - MAE: 40106.5543, MSE: 2503198525.0461, RMSE: 50031.9750, R²: 0.5660, MAPE: 24.51%\n",
            "Test  - MAE: 41222.8582, MSE: 2668651785.3561, RMSE: 51658.9952, R²: 0.5417, MAPE: 26.17%\n",
            "\n",
            "Evaluation for Random Forest Regression:\n",
            "\n",
            "Test Size: 0.3\n",
            "Train - MAE: 33647.0758, MSE: 1758677570.8875, RMSE: 41936.5899, R²: 0.6951, MAPE: 20.49%\n",
            "Test  - MAE: 41867.1083, MSE: 2749298093.3533, RMSE: 52433.7496, R²: 0.5278, MAPE: 26.46%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Benchmark\n"
      ],
      "metadata": {
        "id": "px7orcMN3scO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Comprehensive Model Performance Comparison\n",
        "\n",
        "| **Metric** | **LinearReg** <br> 80:20 <br> Before Tuning <br> Train | **LinearReg** <br> 80:20 <br> Before Tuning <br> Test | **LinearReg** <br> 80:20 <br> After Tuning <br> Train | **LinearReg** <br> 80:20 <br> After Tuning <br> Test | **LinearReg** <br> 70:30 <br> Before Tuning <br> Train | **LinearReg** <br> 70:30 <br> Before Tuning <br> Test | **LinearReg** <br> 70:30 <br> After Tuning <br> Train | **LinearReg** <br> 70:30 <br> After Tuning <br> Test | **RandomForReg** <br> 80:20 <br> Before Tuning <br> Train | **RandomForReg** <br> 80:20 <br> Before Tuning <br> Test | **RandomForReg** <br> 80:20 <br> After Tuning <br> Train | **RandomForReg** <br> 80:20 <br> After Tuning <br> Test | **RandomForReg** <br> 70:30 <br> Before Tuning <br> Train | **RandomForReg** <br> 70:30 <br> Before Tuning <br> Test | **RandomForReg** <br> 70:30 <br> After Tuning <br> Train | **RandomForReg** <br> 70:30 <br> After Tuning <br> Test |\n",
        "|------------|--------------------------------------------------------------|--------------------------------------------------------------|------------------------------------------------------------|------------------------------------------------------------|--------------------------------------------------------------|--------------------------------------------------------------|------------------------------------------------------------|------------------------------------------------------------|--------------------------------------------------------------|--------------------------------------------------------------|------------------------------------------------------------|------------------------------------------------------------|--------------------------------------------------------------|--------------------------------------------------------------|------------------------------------------------------------|------------------------------------------------------------|\n",
        "| **MAE**    | 40,356.50                                                     | 40,765.45                                                     | 40,332.06                                                   | 40,857.80                                                   | 40,427.54                                                     | 40,475.31                                                     | 40,106.55                                                   | 41,222.86                                                   | 15,843.02                                                     | 43,045.79                                                     | 34,213.08                                                   | 41,542.50                                                   | 15,959.90                                                     | 42,995.93                                                     | 33,647.08                                                   | 41,867.11                                                   |\n",
        "| **MSE**    | 2,549,096,747.45                                               | 2,564,777,435.99                                               | 2,531,183,459.43                                             | 2,636,110,412.81                                             | 2,552,133,934.33                                               | 2,553,086,568.96                                               | 2,503,198,525.05                                             | 2,668,651,785.36                                             | 403,223,965.38                                               | 2,887,255,915.97                                               | 1,817,997,301.75                                             | 2,725,642,623.04                                             | 407,012,108.16                                               | 2,915,664,938.01                                               | 1,758,677,570.89                                             | 2,749,298,093.35                                             |\n",
        "| **RMSE**   | 50,488.58                                                     | 50,643.63                                                     | 50,310.87                                                   | 51,343.07                                                   | 50,518.65                                                     | 50,528.08                                                     | 50,031.98                                                   | 51,658.99                                                   | 20,080.44                                                     | 53,733.19                                                     | 42,637.98                                                   | 52,207.69                                                   | 20,228.30                                                     | 53,996.90                                                     | 41,936.59                                                   | 52,433.75                                                   |\n",
        "| **R²**    | 0.5551                                                       | 0.5732                                                       | 0.5632                                                     | 0.5417                                                     | 0.5548                                                       | 0.5680                                                       | 0.5660                                                     | 0.5417                                                     | 0.9296                                                       | 0.5195                                                       | 0.6862                                                     | 0.5261                                                     | 0.9286                                                       | 0.5078                                                       | 0.6951                                                     | 0.5278                                                     |\n",
        "| **MAPE**   | 24.51%                                                       | 27.40%                                                       | 24.79%                                                     | 25.79%                                                     | 24.42%                                                       | 26.79%                                                       | 24.51%                                                     | 26.17%                                                     | 9.49%                                                        | 28.83%                                                       | 20.98%                                                     | 26.16%                                                     | 9.53%                                                        | 28.22%                                                       | 20.49%                                                     | 26.46%                                                     |\n"
      ],
      "metadata": {
        "id": "_0gWxs-F1kq2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Summary**\n",
        "\n",
        "*Linear Regression:*\n",
        "        \n",
        "The performance metrics for Linear Regression remained mostly unchanged after tuning. The MAE, MSE, RMSE, R^2, and MAPE values are similar before and after tuning, indicating that the tuning process did not significantly affect the Linear Regression model's performance.\n",
        "\n",
        "*Random Forest Regressor:*\n",
        "- Before Tuning:\n",
        "  - Shows very high performance on the training data with a very high R^2 and low MAE, MSE, and RMSE values. However, the performance on the test data was much lower, indicating potential overfitting.\n",
        "- After Tuning:\n",
        "  - The performance improved on the test data, with better R^2 and lower MAE values compared to before tuning. However, the model still exhibits a significant difference between training and test metrics, suggesting room for further improvement.\n",
        "\n",
        "Overall, tuning had a more substantial impact on the Random Forest Regressor, improving its test performance, while the Linear Regression metrics remained relatively stable. The Random Forest Regressor at the 70:30 split appears to perform better after tuning considering the metrics are slightly better on the test set, except for the R^2 which is minimally lower."
      ],
      "metadata": {
        "id": "YknMHDGMAV17"
      }
    }
  ]
}